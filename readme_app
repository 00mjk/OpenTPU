__Application__

1. Simple one hot 2-layer NN

gen_one_hot.py generates 8b-int typed random squre matrix as training data and vector as label, example usage:
    
    python gen_one_hot.py --path simple_train --shape 8 8 --range -5 5
    python gen_one_hot.py --path simple_train_label --shape 8 1 --range 0 2

simple_nn.py trains a simple 2-layer nn on the given train/label dataset and writes the weights into a file, example usage (run gen_one_hot example first to generate the files):
    
    python simple_nn.py --path simple_train.npy --label simple_train_label.npy

After running the above command, two files are generated: simple_nn_weight_dram.npy is the 8b-int typed weight dram that the OpenTPU operates on, simple_nn_gt is the pickled ground truth 32b-float resulits and weights. To run with OpenTPU, a test file must also be generated, example usage:

    python gen_one_hot.py --path simple_test --shape 100 8 --range 1, 9

simple_nn.a is the assembly program for this simple nn.

2. Tensorflow DNN regression

Although applications written in any high-level nn framework can be used, here we use tensorflow as an example.

tf_nn.py trains a MLP regressor on the Boston Housing Dataset (https://archive.ics.uci.edu/ml/datasets/housing). Example usage:
    
    python tf_nn.py --N 10 --save-input-path boston_input --save-weight-path boston_weights --save-output-path boston_output
    python tf_nn.py --N 10 --save-input-path boston_input --save-weight-path boston_weights --save-output-path boston_output --raw

After running the above command, four files are generated: gt32.npy holds the ground truth prediction values, boston_input.npy holds the input test cases which is used as the host memeory for OpenTPU, boston_output.npy holds all the intermediate output values, and boston_weights.npy holds the weight matrices which are used as the weight dram for OpenTPU.

Adding --raw to the command generates 32b-float typed files instead of 8b ints.

